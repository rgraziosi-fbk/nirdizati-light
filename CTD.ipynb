{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcbb06e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import json\n",
    "import pm4py\n",
    "from log_distance_measures.config import EventLogIDs\n",
    "from log_distance_measures.control_flow_log_distance import control_flow_log_distance\n",
    "from log_distance_measures.circadian_event_distribution import circadian_event_distribution_distance\n",
    "from log_distance_measures.config import AbsoluteTimestampType, DEFAULT_CSV_IDS, discretize_to_hour\n",
    "from log_distance_measures.relative_event_distribution import relative_event_distribution_distance\n",
    "from log_distance_measures.n_gram_distribution import n_gram_distribution_distance\n",
    "from log_distance_measures.config import AbsoluteTimestampType, DEFAULT_CSV_IDS, discretize_to_hour\n",
    "from log_distance_measures.relative_event_distribution import relative_event_distribution_distance\n",
    "from log_distance_measures.circadian_event_distribution import circadian_event_distribution_distance\n",
    "from log_distance_measures.config import AbsoluteTimestampType, DEFAULT_CSV_IDS\n",
    "from log_distance_measures.absolute_event_distribution import absolute_event_distribution_distance\n",
    "from log_distance_measures.case_arrival_distribution import case_arrival_distribution_distance\n",
    "from log_distance_measures.cycle_time_distribution import cycle_time_distribution_distance\n",
    "import glob\n",
    "from log_distance_measures.config import DistanceMetric\n",
    "from log_distance_measures.earth_movers_distance import earth_movers_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d6aa387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.log import log as lg\n",
    "\n",
    "def prefix_to_log(df, max_prefix):\n",
    "    new_log = lg.EventLog()\n",
    "    dic = dict()\n",
    "    for index, row in df.iterrows():\n",
    "        case_id = row['trace_id']\n",
    "        new_case = lg.Trace({'caseid': case_id})\n",
    "        for i in range(1, max_prefix):\n",
    "            prefix = 'prefix_' + str(i)\n",
    "            event = lg.Event()\n",
    "            event['concept_name'] = row[prefix]\n",
    "            event['start:timestamp'] = row['start:timestamp_'+str(i)]\n",
    "            event['time:timestamp'] =  row['time:timestamp_'+str(i)]\n",
    "            new_case.insert(i, event)\n",
    "        new_log.append(new_case)\n",
    "    return new_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08e03ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train = pd.read_csv(\"/Users/francescameneghello/Documents/GitHub/nirdizati-light/experiments/new_logs/\" +\n",
    "                             \"Productions_train_df_cf_aug_0.1_pref_len_20.csv\")\n",
    "#original_train = prefix_to_log(original_train, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05574265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Round Grinding']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(original_train[original_train.trace_id == 'Case178']['prefix_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2dd8a706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case178\n",
      "Round Grinding prefix_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w4/c4bpfq1j4l94r7q69c434q0c0000gn/T/ipykernel_17124/1226155789.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_new = pd.concat([df_new, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'prefix_2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w4/c4bpfq1j4l94r7q69c434q0c0000gn/T/ipykernel_17124/1226155789.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m original_train = pd.read_csv(\"/Users/francescameneghello/Documents/GitHub/nirdizati-light/experiments/new_logs/\" +\n\u001b[1;32m     15\u001b[0m                              \"Productions_train_df_cf_aug_0.1_pref_len_20.csv\")\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtransform_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/w4/c4bpfq1j4l94r7q69c434q0c0000gn/T/ipykernel_17124/1226155789.py\u001b[0m in \u001b[0;36mtransform_df\u001b[0;34m(df, max_prefix)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'prefix_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prefix_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"trace_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcase_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"task\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"start_timestamp\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start:timestamp_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"time_timestamp\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time:timestamp_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mdf_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'prefix_2'"
     ]
    }
   ],
   "source": [
    "def transform_df(df, max_prefix):\n",
    "    columns = [\"trace_id\", \"task\", \"start_timestamp\", \"time_timestamp\"]\n",
    "    df_new = pd.DataFrame(columns=columns)\n",
    "    for index, row in df.iterrows():\n",
    "        case_id = row['trace_id']\n",
    "        print(case_id)\n",
    "        for i in range(1, max_prefix):\n",
    "            prefix = 'prefix_' + str(i)\n",
    "            print(row['prefix_2'], prefix)\n",
    "            row = {\"trace_id\": case_id, \"task\": row[prefix], \"start_timestamp\": row['start:timestamp_'+str(i)], \"time_timestamp\": row['time:timestamp_'+str(i)]}\n",
    "            df_new = pd.concat([df_new, pd.DataFrame([row])], ignore_index=True)\n",
    "    return df_new\n",
    "\n",
    "original_train = pd.read_csv(\"/Users/francescameneghello/Documents/GitHub/nirdizati-light/experiments/new_logs/\" +\n",
    "                             \"Productions_train_df_cf_aug_0.1_pref_len_20.csv\")\n",
    "transform_df(original_train, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cacb7201",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #0 has length 1; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w4/c4bpfq1j4l94r7q69c434q0c0000gn/T/ipykernel_17124/3189230288.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moriginal_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix_to_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moriginal_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm4py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#original_train[event_log_ids.start_time] = pd.to_datetime(original_train[event_log_ids.start_time], utc=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pm4py/convert.py\u001b[0m in \u001b[0;36mconvert_to_dataframe\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpm4py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTO_DATA_FRAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pm4py/objects/conversion/log/converter.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(log, parameters, variant)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVariants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTO_EVENT_LOG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvariant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pm4py/objects/conversion/log/variants/to_data_frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(log, parameters)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_event_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mtransf_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransf_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pm4py/objects/conversion/log/variants/to_data_frame.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_event_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mtransf_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransf_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dictionary update sequence element #0 has length 1; 2 is required"
     ]
    }
   ],
   "source": [
    "original_train = pd.read_csv(\"/Users/francescameneghello/Documents/GitHub/nirdizati-light/experiments/new_logs/\" +\n",
    "                             \"Productions_train_df_cf_aug_0.1_pref_len_20.csv\")\n",
    "original_train = prefix_to_log(original_train, 9)\n",
    "\n",
    "original_train = pm4py.convert_to_dataframe(original_train)\n",
    "\n",
    "#original_train[event_log_ids.start_time] = pd.to_datetime(original_train[event_log_ids.start_time], utc=True)\n",
    "#original_train[event_log_ids.end_time] = pd.to_datetime(original_train[event_log_ids.end_time], utc=True)\n",
    "\n",
    "event_log_ids = EventLogIDs(  # These values are stored in DEFAULT_CSV_IDS\n",
    "        case=\"caseid\",\n",
    "        activity=\"task\",\n",
    "        start_time=\"start:timestamp\",\n",
    "        end_time=\"time:timestamp\"\n",
    "    )\n",
    "\n",
    "path = '/Users/francescameneghello/Documents/GitHub/nirdizati-light/experiments/new_logs/ConsultaDataMining201618/ConsultaDataMining201618_train_df_cf_simulated_aug_*'\n",
    "#all_file = glob.glob(path_dict[t][0])\n",
    "\n",
    "distance = cycle_time_distribution_distance(\n",
    "                            original_train, event_log_ids,  # First event log and its column id mappings\n",
    "                            original_train, event_log_ids,  # Second event log and its column id mappings\n",
    "                            bin_size=pd.Timedelta(hours=1)  # Bins of 1 hour\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3688f2df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
